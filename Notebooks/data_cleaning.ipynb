{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e3dd2c",
   "metadata": {},
   "source": [
    "In this notebook we will load in the relevant data from the Youtube trending data set, which for this analysis will be the videos from the United States and Canada. First we will load the necessary packages and then read in the .csv's ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5b7a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data_us = pd.read_csv('data/USvideos.csv')\n",
    "data_ca = pd.read_csv('data/CAvideos.csv')\n",
    "data = data_us.append(data_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99f0682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jonathan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jonathan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id trending_date  \\\n",
      "0  2kyS6SvSYSE      17.14.11   \n",
      "1  1ZAPwfrtAFY      17.14.11   \n",
      "2  5qpjK5DgCt4      17.14.11   \n",
      "3  puqaWrEC7tY      17.14.11   \n",
      "4  d380meD0W0M      17.14.11   \n",
      "\n",
      "                                               title          channel_title  \\\n",
      "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
      "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
      "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
      "4                           I Dare You: GOING BALD!?               nigahiga   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           22  2017-11-13T17:13:01.000Z   \n",
      "1           24  2017-11-13T07:30:00.000Z   \n",
      "2           23  2017-11-12T19:05:24.000Z   \n",
      "3           24  2017-11-13T11:00:04.000Z   \n",
      "4           24  2017-11-12T18:01:41.000Z   \n",
      "\n",
      "                                                tags    views   likes  \\\n",
      "0                                    SHANtell martin   748374   57527   \n",
      "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
      "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
      "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
      "\n",
      "   dislikes  comment_count                                  thumbnail_link  \\\n",
      "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
      "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
      "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
      "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "\n",
      "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0              False             False                   False   \n",
      "1              False             False                   False   \n",
      "2              False             False                   False   \n",
      "3              False             False                   False   \n",
      "4              False             False                   False   \n",
      "\n",
      "                                         description  \n",
      "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
      "1  One year after the presidential election, John...  \n",
      "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
      "3  Today we find out if Link is a Nickelback amat...  \n",
      "4  I know it's been a while since we did this sho...  \n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  81830.000000  8.183000e+04  8.183000e+04  8.183000e+04   8.183000e+04\n",
      "mean      20.383649  1.754415e+06  5.693911e+04  2.861005e+03   6.746303e+03\n",
      "std        7.194716  5.785451e+06  1.879156e+05  2.455480e+04   3.060427e+04\n",
      "min        1.000000  5.490000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       17.000000  1.781945e+05  3.301000e+03  1.360000e+02   5.050000e+02\n",
      "50%       24.000000  4.961600e+05  1.283400e+04  4.380000e+02   1.550000e+03\n",
      "75%       24.000000  1.355388e+06  4.096175e+04  1.421000e+03   4.626000e+03\n",
      "max       43.000000  2.252119e+08  5.613827e+06  1.674420e+06   1.361580e+06\n",
      "(81830, 16)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6efd892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               1866\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e65d2",
   "metadata": {},
   "source": [
    "This data is very clean right off the bat, only 1,866 videos trended without a description, but since this is not a column of interest for us anyway, we can disregard it. Now we can make sure that the data types are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343ea411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                  object\n",
       "trending_date             object\n",
       "title                     object\n",
       "channel_title             object\n",
       "category_id                int64\n",
       "publish_time              object\n",
       "tags                      object\n",
       "views                      int64\n",
       "likes                      int64\n",
       "dislikes                   int64\n",
       "comment_count              int64\n",
       "thumbnail_link            object\n",
       "comments_disabled           bool\n",
       "ratings_disabled            bool\n",
       "video_error_or_removed      bool\n",
       "description               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec7b2c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                          object\n",
       "trending_date             datetime64[ns]\n",
       "title                             object\n",
       "channel_title                     object\n",
       "category_id                        int64\n",
       "publish_time                      object\n",
       "tags                              object\n",
       "views                              int64\n",
       "likes                              int64\n",
       "dislikes                           int64\n",
       "comment_count                      int64\n",
       "thumbnail_link                    object\n",
       "comments_disabled                   bool\n",
       "ratings_disabled                    bool\n",
       "video_error_or_removed              bool\n",
       "description                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['trending_date'] =pd.to_datetime(data['trending_date'], format = '%y.%d.%m')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7282df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                               object\n",
       "trending_date                  datetime64[ns]\n",
       "title                                  object\n",
       "channel_title                          object\n",
       "category_id                             int64\n",
       "publish_time              datetime64[ns, UTC]\n",
       "tags                                   object\n",
       "views                                   int64\n",
       "likes                                   int64\n",
       "dislikes                                int64\n",
       "comment_count                           int64\n",
       "thumbnail_link                         object\n",
       "comments_disabled                        bool\n",
       "ratings_disabled                         bool\n",
       "video_error_or_removed                   bool\n",
       "description                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['publish_time'] = pd.to_datetime(data['publish_time']) \n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d4dff",
   "metadata": {},
   "source": [
    "Now we make some potentially enlightening groupings for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4e62a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_title\n",
      "#AndresSTyle             4.433970e+05\n",
      "#Mind Warehouse          1.160725e+06\n",
      "#SeekingTheTruth         1.190110e+05\n",
      "* Martyna *              1.499100e+04\n",
      "- 欢迎订阅 -浙江卫视【奔跑吧】官方频道    1.354697e+06\n",
      "                             ...     \n",
      "창조영감클럽                   7.595300e+04\n",
      "타우TV                     4.719190e+05\n",
      "포스트쉐어                    1.658045e+06\n",
      "포크포크                     6.059360e+05\n",
      "활력소TV                    8.207900e+05\n",
      "Name: views, Length: 6251, dtype: float64\n",
      "Stored 'full_views_by_channel' (Series)\n"
     ]
    }
   ],
   "source": [
    "channels = data.set_index('channel_title').groupby('channel_title').mean()\n",
    "print(channels.views)\n",
    "full_views_by_channel = channels.views\n",
    "%store full_views_by_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daddc4a2",
   "metadata": {},
   "source": [
    "We see that the 81830 trending videos over the time period were created by a scant 6251 creators. We will now cut that down even more by removing from our analysis channels exclusively for psoting professional music, since these are not patterns that can be followed by a typical youtube creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b513896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77631, 16)\n"
     ]
    }
   ],
   "source": [
    "strings_drop = 'VEVO'\n",
    "\n",
    "music_channels = data['channel_title'].str.contains(strings_drop)\n",
    "print(data[~music_channels].shape)\n",
    "data1 = data[~music_channels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9836935",
   "metadata": {},
   "source": [
    "This cuts out about 25,000 videos, but will leave us hopefully with a more instructive model. Next we want to remove the titles with non-english characters, since this will be a NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad60843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9        Why the rise of the robots won’t mean the end ...\n",
      "57       Kellyanne Conway on Roy Moore This Week Abc: T...\n",
      "68       Watch Norman Reedus Come Face to Face with his...\n",
      "75       Rosie O’Donnell On Donald Trump’s Hostility To...\n",
      "76       Mayo Clinic's first face transplant patient me...\n",
      "                               ...                        \n",
      "40866            سوحليفة: الحلقة 28 | Souhlifa: Episode 28\n",
      "40872    NCT 미니게임천국 #3: 최강 손가락 컨트롤러 (Professional Finge...\n",
      "40875          Вечер с Владимиром Соловьевым от 13.06.2018\n",
      "40878    KINGDOM HEARTS III – SQUARE ENIX E3 SHOWCASE 2...\n",
      "40880                     【完整版】遇到恐怖情人該怎麼辦？2018.06.13小明星大跟班\n",
      "Name: title, Length: 10779, dtype: object\n"
     ]
    }
   ],
   "source": [
    "english = data1.title.map(lambda x: x.isascii())\n",
    "print(data1.title[~english])\n",
    "data2 = data1[english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d6970ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_title\n",
      "#AndresSTyle          4.433970e+05\n",
      "#Mind Warehouse       1.160725e+06\n",
      "* Martyna *           1.499100e+04\n",
      "078jordan1            1.746905e+05\n",
      "0b1knob               6.463600e+04\n",
      "                          ...     \n",
      "Émile Roy             5.847500e+03\n",
      "Легендарный Киллер    5.669440e+05\n",
      "Никита Ордынский      1.313062e+06\n",
      "ХайП                  1.342340e+05\n",
      "【JindaRK】             2.496670e+05\n",
      "Name: views, Length: 4965, dtype: float64\n",
      "Stored 'views_by_channel' (Series)\n"
     ]
    }
   ],
   "source": [
    "channels = data2.set_index('channel_title').groupby('channel_title').mean()\n",
    "print(channels.views)\n",
    "views_by_channel = channels.views\n",
    "%store views_by_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa6807",
   "metadata": {},
   "source": [
    "I want to preserve the information from the titles of all-caps and puncuation like exclamation points and question marks so I will create a separate column for each before preparing the title column for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32c95957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id trending_date  \\\n",
      "0  2kyS6SvSYSE    2017-11-14   \n",
      "1  1ZAPwfrtAFY    2017-11-14   \n",
      "2  5qpjK5DgCt4    2017-11-14   \n",
      "3  puqaWrEC7tY    2017-11-14   \n",
      "4  d380meD0W0M    2017-11-14   \n",
      "\n",
      "                                               title          channel_title  \\\n",
      "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
      "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
      "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
      "4                           I Dare You: GOING BALD!?               nigahiga   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           22 2017-11-13 17:13:01+00:00   \n",
      "1           24 2017-11-13 07:30:00+00:00   \n",
      "2           23 2017-11-12 19:05:24+00:00   \n",
      "3           24 2017-11-13 11:00:04+00:00   \n",
      "4           24 2017-11-12 18:01:41+00:00   \n",
      "\n",
      "                                                tags    views   likes  \\\n",
      "0                                    SHANtell martin   748374   57527   \n",
      "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
      "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
      "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
      "\n",
      "   dislikes  comment_count                                  thumbnail_link  \\\n",
      "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
      "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
      "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
      "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "\n",
      "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0              False             False                   False   \n",
      "1              False             False                   False   \n",
      "2              False             False                   False   \n",
      "3              False             False                   False   \n",
      "4              False             False                   False   \n",
      "\n",
      "                                         description  all_caps  exclamation  \\\n",
      "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...      True        False   \n",
      "1  One year after the presidential election, John...     False        False   \n",
      "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...     False        False   \n",
      "3  Today we find out if Link is a Nickelback amat...     False        False   \n",
      "4  I know it's been a while since we did this sho...     False         True   \n",
      "\n",
      "   question  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3      True  \n",
      "4      True  \n",
      "(66852, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-a8edd7d42cd0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['all_caps'] = all_caps\n",
      "<ipython-input-67-a8edd7d42cd0>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['exclamation'] = exclamation\n",
      "<ipython-input-67-a8edd7d42cd0>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['question'] = question\n"
     ]
    }
   ],
   "source": [
    "all_caps = data2['title'].str.isupper()\n",
    "data2['all_caps'] = all_caps\n",
    "exclamation = data2['title'].str.contains('\\!')\n",
    "question = data2['title'].str.contains('\\?')\n",
    "data2['exclamation'] = exclamation\n",
    "data2['question'] = question\n",
    "\n",
    "print(data2.head())\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ef686",
   "metadata": {},
   "source": [
    "Now we do some pre-processing specific to NLP. This involves removing stop words, punction, and capitilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "febef915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id trending_date  \\\n",
      "0  2kyS6SvSYSE    2017-11-14   \n",
      "1  1ZAPwfrtAFY    2017-11-14   \n",
      "2  5qpjK5DgCt4    2017-11-14   \n",
      "3  puqaWrEC7tY    2017-11-14   \n",
      "4  d380meD0W0M    2017-11-14   \n",
      "\n",
      "                                               title          channel_title  \\\n",
      "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
      "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
      "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
      "4                           I Dare You: GOING BALD!?               nigahiga   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           22 2017-11-13 17:13:01+00:00   \n",
      "1           24 2017-11-13 07:30:00+00:00   \n",
      "2           23 2017-11-12 19:05:24+00:00   \n",
      "3           24 2017-11-13 11:00:04+00:00   \n",
      "4           24 2017-11-12 18:01:41+00:00   \n",
      "\n",
      "                                                tags    views   likes  \\\n",
      "0                                    SHANtell martin   748374   57527   \n",
      "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
      "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
      "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
      "\n",
      "   dislikes  ...                                  thumbnail_link  \\\n",
      "0      2966  ...  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
      "1      6146  ...  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
      "2      5339  ...  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3       666  ...  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
      "4      1989  ...  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "\n",
      "  comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0             False             False                   False   \n",
      "1             False             False                   False   \n",
      "2             False             False                   False   \n",
      "3             False             False                   False   \n",
      "4             False             False                   False   \n",
      "\n",
      "                                         description all_caps  exclamation  \\\n",
      "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...     True        False   \n",
      "1  One year after the presidential election, John...    False        False   \n",
      "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...    False        False   \n",
      "3  Today we find out if Link is a Nickelback amat...    False        False   \n",
      "4  I know it's been a while since we did this sho...    False         True   \n",
      "\n",
      "   question                                       title_simple  \\\n",
      "0     False                                 want talk marriage   \n",
      "1     False  trump presidency  last week tonight john olive...   \n",
      "2     False  racist superman  rudy mancuso  king bach  lele...   \n",
      "3      True                      nickelback lyrics  real fake    \n",
      "4      True                                 dare  going bald     \n",
      "\n",
      "                                          title_stop  \n",
      "0                                 want talk marriage  \n",
      "1  trump presidency : last week tonight john oliv...  \n",
      "2  racist superman | rudy mancuso , king bach & l...  \n",
      "3                    nickelback lyrics : real fake ?  \n",
      "4                              dare : going bald ! ?  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-dea29cbed6ab>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[\"title_stop\"] = data2['title'].apply(lambda x: ' '.join([word for word in word_tokenize(x.lower()) if word not in (stop_words)]))\n",
      "<ipython-input-84-dea29cbed6ab>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data2['title_simple'] = data2['title_stop'].str.replace('[^\\w\\s]','')\n",
      "<ipython-input-84-dea29cbed6ab>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['title_simple'] = data2['title_stop'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "#example_sent = 'This is a sample sentence, showing off the stop words filtration'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data2[\"title_stop\"] = data2['title'].apply(lambda x: ' '.join([word for word in word_tokenize(x.lower()) if word not in (stop_words)]))\n",
    "data2['title_simple'] = data2['title_stop'].str.replace('[^\\w\\s]','')\n",
    "print(data2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100527a1",
   "metadata": {},
   "source": [
    "Finally we write this dataframe to a csv for the next stage of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2be64a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'clean_data/clean_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-34073d85e57f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clean_data/clean_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'clean_data/clean_data.csv'"
     ]
    }
   ],
   "source": [
    "data2.to_csv('clean_data/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
